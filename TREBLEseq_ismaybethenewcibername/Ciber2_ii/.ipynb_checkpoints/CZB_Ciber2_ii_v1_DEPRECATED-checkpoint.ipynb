{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67ce67e4",
   "metadata": {},
   "source": [
    "Turned this notebook into the .py scripts in empchase/Scripts/ciber_experiment/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a83e21f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/global/scratch/users/empchase/Ciber2_ii'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e48e0205",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import time\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import csv\n",
    "import concurrent.futures\n",
    "\n",
    "import duckdb\n",
    "conn = duckdb.connect('/global/scratch/users/empchase/A10_sequencing/v2/analysis2.db') # create an in-memory database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f3d0651",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/global/scratch/projects/fc_mvslab/data/sequencing/CZB_Apr2024/20240425/EC_Ciber2/results/assembled_reads/AD_reads/sample2/AD_2_10_S46.fastq.gz.assembled.fastq', '/global/scratch/projects/fc_mvslab/data/sequencing/CZB_Apr2024/20240425/EC_Ciber2/results/assembled_reads/AD_reads/sample2/AD_2_0_S44.fastq.gz.assembled.fastq', '/global/scratch/projects/fc_mvslab/data/sequencing/CZB_Apr2024/20240425/EC_Ciber2/results/assembled_reads/AD_reads/sample2/AD_2_15_S47.fastq.gz.assembled.fastq', '/global/scratch/projects/fc_mvslab/data/sequencing/CZB_Apr2024/20240425/EC_Ciber2/results/assembled_reads/AD_reads/sample2/AD_2_5_S45.fastq.gz.assembled.fastq', '/global/scratch/projects/fc_mvslab/data/sequencing/CZB_Apr2024/20240425/EC_Ciber2/results/assembled_reads/AD_reads/sample2/AD_2_180_S49.fastq.gz.assembled.fastq', '/global/scratch/projects/fc_mvslab/data/sequencing/CZB_Apr2024/20240425/EC_Ciber2/results/assembled_reads/AD_reads/sample2/AD_2_30_S48.fastq.gz.assembled.fastq']\n",
      "['/global/scratch/projects/fc_mvslab/data/sequencing/CZB_Apr2024/20240425/EC_Ciber2/results/assembled_reads/RPTR_reads/sample2RPTR_2_5_S64.fastq.gz.assembled.fastq', '/global/scratch/projects/fc_mvslab/data/sequencing/CZB_Apr2024/20240425/EC_Ciber2/results/assembled_reads/RPTR_reads/sample2RPTR_2_240_S69.fastq.gz.assembled.fastq', '/global/scratch/projects/fc_mvslab/data/sequencing/CZB_Apr2024/20240425/EC_Ciber2/results/assembled_reads/RPTR_reads/sample2RPTR_2_10_S65.fastq.gz.assembled.fastq', '/global/scratch/projects/fc_mvslab/data/sequencing/CZB_Apr2024/20240425/EC_Ciber2/results/assembled_reads/RPTR_reads/sample2RPTR_2_0_S63.fastq.gz.assembled.fastq', '/global/scratch/projects/fc_mvslab/data/sequencing/CZB_Apr2024/20240425/EC_Ciber2/results/assembled_reads/RPTR_reads/sample2RPTR_2_15_S66.fastq.gz.assembled.fastq', '/global/scratch/projects/fc_mvslab/data/sequencing/CZB_Apr2024/20240425/EC_Ciber2/results/assembled_reads/RPTR_reads/sample2RPTR_2_30_S67.fastq.gz.assembled.fastq', '/global/scratch/projects/fc_mvslab/data/sequencing/CZB_Apr2024/20240425/EC_Ciber2/results/assembled_reads/RPTR_reads/sample2RPTR_2_180_S68.fastq.gz.assembled.fastq']\n"
     ]
    }
   ],
   "source": [
    "#where are the reads\n",
    "adpath = '/global/scratch/projects/fc_mvslab/data/sequencing/CZB_Apr2024/20240425/EC_Ciber2/results/assembled_reads/AD_reads/sample2/'\n",
    "rptrpath = '/global/scratch/projects/fc_mvslab/data/sequencing/CZB_Apr2024/20240425/EC_Ciber2/results/assembled_reads/RPTR_reads/sample2'\n",
    "\n",
    "addirectory = os.fsencode(adpath)\n",
    "rptrdirectory = os.fsencode(rptrpath)\n",
    "\n",
    "AD1files = []\n",
    "\n",
    "for file in os.listdir(addirectory):\n",
    "    filename = os.fsdecode(file)\n",
    "#     x = filename.split('_')\n",
    "#     filename = path + filename\n",
    "    \n",
    "    if filename.endswith('.fastq'): \n",
    "        x = filename.split('_')\n",
    "        filename = adpath + filename\n",
    "#         print(x)\n",
    "        if 'AD' in x:\n",
    "            AD1files.append(filename)\n",
    "            \n",
    "            \n",
    "RPTR1files = [] #nt: one file ends with .txt, and is not in fastq format, so I have to manually input that into analysis later\n",
    "\n",
    "for file in os.listdir(rptrdirectory):\n",
    "    filename = os.fsdecode(file)\n",
    "    if filename.endswith('.fastq'): #or filename.endswith('.txt')\n",
    "        x = filename.split('_')\n",
    "        filename = rptrpath + filename\n",
    "        if 'RPTR' in x:\n",
    "            RPTR1files.append(filename)\n",
    "            \n",
    "print(AD1files)\n",
    "print(RPTR1files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "181752fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "print(len(AD1files))\n",
    "print(len(RPTR1files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54778924",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complement(seq):\n",
    "    complement = {'A': 'T', 'C': 'G', 'G': 'C', 'T': 'A', 'N':'N', 'X':'X'} \n",
    "    bases = list(seq) \n",
    "    bases = [complement[base] for base in bases] \n",
    "    return ''.join(bases)\n",
    "def reverse_complement(s):\n",
    "        return complement(s[::-1])\n",
    "    \n",
    "    \n",
    "def getmid(seq, pre, post, bclen):\n",
    "    # seq = the sequence to parse\n",
    "    # pre = substring that precedes piece of interest\n",
    "    # post = substring that follows piece of interest\n",
    "    # returns piece of interest\n",
    "\n",
    "    re_key = pre + \"(.*)\"+ post \n",
    "    poi_search = re.search(re_key, seq)\n",
    "    if poi_search is None:\n",
    "        #the barcode will be called X\n",
    "        poi = \"X\"\n",
    "        \n",
    "        #then we search for which restriction site had the error\n",
    "        #regex for the bc we want to ignore\n",
    "        w = \"(.{\"+str(bclen)+\"})\" \n",
    "        pre_re = pre + w + \"(.{7})\"\n",
    "        pre_search = re.search(pre_re, seq)\n",
    "        post_re = \"(\\w{7})\" + w + post\n",
    "        post_search = re.search(post_re, seq)\n",
    "        \n",
    "        if pre_search is None and post_search is None:\n",
    "            a = 'X'\n",
    "            z = 'X'\n",
    "        elif pre_search is None:\n",
    "            poi = post_search.group(2)\n",
    "            a = post_search.group(1)\n",
    "            z = post\n",
    "        elif post_search is None:\n",
    "            poi = pre_search.group(1)\n",
    "            z = pre_search.group(2)\n",
    "            a = pre\n",
    "        else:\n",
    "            a = \"Z\"\n",
    "            z = 'Z'            \n",
    "    else:\n",
    "        poi = poi_search.group(1)\n",
    "        a = pre\n",
    "        z = post\n",
    "    \n",
    "    return poi, a, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bee6a850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20728\n"
     ]
    }
   ],
   "source": [
    "#putative consensus sequences ***reverse complement of snapgene***\n",
    "adp = 'CGGGCCC'#7 bp ; beforeAD barcode in read1\n",
    "adf = 'GGCGCGC' #7bp ; after AD barcode in read1\n",
    "\n",
    "rpp = 'AGCGGCC' #7bp ; before rptr barcode in read1\n",
    "rpf = 'CTCGAGT' #7 bp ; after rptr barcode in read1\n",
    "\n",
    "tp = \"TAGTCA\"\n",
    "tf = \"GCTAGC\"\n",
    "\n",
    "#get list of designed tiles\n",
    "a10design = '/global/scratch/users/empchase/A10_sequencing/v2/a10_designfile.csv'\n",
    "\n",
    "a10dt = []\n",
    "\n",
    "with open(a10design, 'r') as f:\n",
    "    for line in f:\n",
    "        if \"ArrayDNA\" in line:\n",
    "            pass\n",
    "        else:\n",
    "            a10dt.append(line.strip())\n",
    "# print(a10dt[:5])\n",
    "# print(len(a10dt))#20783\n",
    "\n",
    "#create a dictionary of values\n",
    "dtiles = {}\n",
    "for i in a10dt:\n",
    "    dtiles[i] = 1\n",
    "    \n",
    "print(len(dtiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3121664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that just looks for RPTR bc\n",
    "def rbc_finder(readfile, bc_pre=rpp, bc_post=rpf, bc_len=14):\n",
    "    #readfile = fastq file -- RPTR files are read1\n",
    "    #default values for the pre/post regions defined in above cell\n",
    "    \n",
    "    # make lists of reads\n",
    "    seqlist = []\n",
    "    with open(readfile, 'r') as fin:\n",
    "        for line in fin:\n",
    "            if line.startswith('@'):\n",
    "                #look at next line to get read sequence, add to list\n",
    "                seq = next(fin)\n",
    "                seq = seq.strip()\n",
    "                seqlist.append(seq)\n",
    "\n",
    "    \n",
    "    #make lists of BCs from list of reads\n",
    "    bc_list = []\n",
    "    bc_lens = []       \n",
    "    for read in seqlist:\n",
    "        bc, prex, postx = getmid(read, bc_pre, bc_post, bc_len)\n",
    "        bc = reverse_complement(bc) #return reverse complement\n",
    "        bc_list.append(bc)\n",
    "        bcl = len(bc)\n",
    "        bc_lens.append(bcl)\n",
    "\n",
    "    #make the dict/df\n",
    "    BC_dict = {\"BCs\":bc_list, \"Length\":bc_lens} \n",
    "    BC_df = pd.DataFrame.from_dict(BC_dict)\n",
    "    \n",
    "    #label df with library name\n",
    "    libname = '_'.join(readfile.split('/')[-1].split('_')[0:6])\n",
    "    BC_df['Library'] = libname\n",
    "    \n",
    "    return BC_df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# function that just looks for Tile/AD bc\n",
    "def adbc_mapper(readfile, tile_pre = tp, tile_post = tf, \n",
    "                  adBC_pre = adp, adBC_post = adf):\n",
    "    #readfile = fastq (ADBC fastqs are typically paired)\n",
    "    # *_pre or *_post = the consensus sequences before or after each feature, defaults defined above\n",
    "    print(readfile + '   ')\n",
    "    # make lists of reads\n",
    "    readlist = []    \n",
    "    with open(readfile, 'r') as fin:\n",
    "        for line in fin:\n",
    "            if line.startswith('@'):\n",
    "                #look at next line to get read sequence, add to list\n",
    "                seq = next(fin)\n",
    "                seq = seq.strip()\n",
    "                readlist.append(seq)\n",
    "                \n",
    "    #make lists of tiles/BCs from list of reads\n",
    "    tile_list = []\n",
    "    tile_lengths= []\n",
    "    \n",
    "    des_query = [] # tells us if tile matches design or not\n",
    "    \n",
    "    adBC_list = []\n",
    "    adBC_lengths = []\n",
    "    \n",
    "    tile_adbc = []\n",
    "   \n",
    "    \n",
    "    for read in readlist:\n",
    "        tile, tpre, tpost = getmid(read, tile_pre, tile_post, 120) #use consensus seq to find tile\n",
    "        tile = reverse_complement(tile)\n",
    "        tile_list.append(tile) #add tile to list\n",
    "        tile_len = len(tile) #find length of tile\n",
    "        tile_lengths.append(tile_len) #add length to list\n",
    "            \n",
    "        if tile in dtiles:\n",
    "            des_query.append(1)\n",
    "        else:\n",
    "            des_query.append(0)\n",
    "#         print(tile)\n",
    "        \n",
    "        adBC, prea, posta = getmid(read, adBC_pre, adBC_post, 11)\n",
    "        adBC = reverse_complement(adBC)\n",
    "        adBC_list.append(adBC)\n",
    "        adBC_len = len(adBC)\n",
    "        adBC_lengths.append(adBC_len)\n",
    "        \n",
    "        tile_adbc.append(tile+'-'+adBC)\n",
    "\n",
    "            \n",
    "    # make the df\n",
    "    tileBC_dict = {\"Tiles\":tile_list, \"T Len\" : tile_lengths, \"Designed\": des_query, \n",
    "                  \"AD BCs\":adBC_list, \"A Len\": adBC_lengths, 'Tile-AD': tile_adbc}\n",
    "    tileBC_df = pd.DataFrame.from_dict(tileBC_dict)\n",
    "    \n",
    "    libname = '_'.join(readfile.split('/')[-1].split('_')[0:6])\n",
    "    tileBC_df['Library'] = libname\n",
    "    \n",
    "    return tileBC_df\n",
    "\n",
    "\n",
    "# function that just looks for bc from nonfastq\n",
    "def bc_finder_seqonly(readfile,bc_pre, bc_post, bc_len):\n",
    "    #readfile is NOT fastq, each line is a sequence\n",
    "    #no defaults\n",
    "\n",
    "    # make lists of reads\n",
    "    seqlist = []\n",
    "    with open(readfile, 'r') as fin:\n",
    "        for line in fin:\n",
    "            seq = line.strip()\n",
    "            seqlist.append(seq)\n",
    "\n",
    "    \n",
    "    #make lists of BCs from list of reads\n",
    "    bc_list = []\n",
    "    bc_lens = []\n",
    "       \n",
    "    for read in seqlist:\n",
    "   \n",
    "        bc, prex, postx = getmid(read, bc_pre, bc_post, bc_len)\n",
    "        bc = reverse_complement(bc) #return reverse complement\n",
    "        bc_list.append(bc)\n",
    "        bcl = len(bc)\n",
    "        bc_lens.append(bcl)\n",
    "        \n",
    "    #make the df\n",
    "    BC_dict = {\"BCs\":bc_list, \"Length\":bc_lens}\n",
    "    BC_df = pd.DataFrame.from_dict(BC_dict)\n",
    "    \n",
    "    #label df with library name\n",
    "    libname = '_'.join(readfile.split('/')[-1].split('_')[0:6])\n",
    "    BC_df['Library'] = libname\n",
    "    \n",
    "    return BC_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39138ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/global/scratch/projects/fc_mvslab/data/sequencing/CZB_Apr2024/20240425/EC_Ciber2/results/assembled_reads/AD_reads/sample2/AD_2_0_S44.fastq.gz.assembled.fastq   /global/scratch/projects/fc_mvslab/data/sequencing/CZB_Apr2024/20240425/EC_Ciber2/results/assembled_reads/AD_reads/sample2/AD_2_10_S46.fastq.gz.assembled.fastq   /global/scratch/projects/fc_mvslab/data/sequencing/CZB_Apr2024/20240425/EC_Ciber2/results/assembled_reads/AD_reads/sample2/AD_2_15_S47.fastq.gz.assembled.fastq   /global/scratch/projects/fc_mvslab/data/sequencing/CZB_Apr2024/20240425/EC_Ciber2/results/assembled_reads/AD_reads/sample2/AD_2_180_S49.fastq.gz.assembled.fastq   /global/scratch/projects/fc_mvslab/data/sequencing/CZB_Apr2024/20240425/EC_Ciber2/results/assembled_reads/AD_reads/sample2/AD_2_5_S45.fastq.gz.assembled.fastq   /global/scratch/projects/fc_mvslab/data/sequencing/CZB_Apr2024/20240425/EC_Ciber2/results/assembled_reads/AD_reads/sample2/AD_2_30_S48.fastq.gz.assembled.fastq   \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "BrokenProcessPool",
     "evalue": "A process in the process pool was terminated abruptly while the future was running or pending.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBrokenProcessPool\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mProcessPoolExecutor() \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m     12\u001b[0m     results \u001b[38;5;241m=\u001b[39m executor\u001b[38;5;241m.\u001b[39mmap(adbc_mapper, AD1files)\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m results:\n\u001b[1;32m     14\u001b[0m         Alist\u001b[38;5;241m.\u001b[39mappend(r)\n\u001b[1;32m     18\u001b[0m finish \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n",
      "File \u001b[0;32m~/.conda/envs/biopython/lib/python3.11/concurrent/futures/process.py:602\u001b[0m, in \u001b[0;36m_chain_from_iterable_of_lists\u001b[0;34m(iterable)\u001b[0m\n\u001b[1;32m    596\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_chain_from_iterable_of_lists\u001b[39m(iterable):\n\u001b[1;32m    597\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;124;03m    Specialized implementation of itertools.chain.from_iterable.\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;124;03m    Each item in *iterable* should be a list.  This function is\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;124;03m    careful not to keep references to yielded objects.\u001b[39;00m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 602\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m element \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m    603\u001b[0m         element\u001b[38;5;241m.\u001b[39mreverse()\n\u001b[1;32m    604\u001b[0m         \u001b[38;5;28;01mwhile\u001b[39;00m element:\n",
      "File \u001b[0;32m~/.conda/envs/biopython/lib/python3.11/concurrent/futures/_base.py:619\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m fs:\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;66;03m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[1;32m    618\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 619\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43m_result_or_cancel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    621\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m _result_or_cancel(fs\u001b[38;5;241m.\u001b[39mpop(), end_time \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic())\n",
      "File \u001b[0;32m~/.conda/envs/biopython/lib/python3.11/concurrent/futures/_base.py:317\u001b[0m, in \u001b[0;36m_result_or_cancel\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 317\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfut\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    319\u001b[0m         fut\u001b[38;5;241m.\u001b[39mcancel()\n",
      "File \u001b[0;32m~/.conda/envs/biopython/lib/python3.11/concurrent/futures/_base.py:456\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "File \u001b[0;32m~/.conda/envs/biopython/lib/python3.11/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mBrokenProcessPool\u001b[0m: A process in the process pool was terminated abruptly while the future was running or pending."
     ]
    }
   ],
   "source": [
    "#Redo to be parallel\n",
    "\n",
    "# testadlist = [AD1files[1], AD1files[-1], AD1files[2]]\n",
    "\n",
    "# # make df out of each fastq file\n",
    "Alist = []\n",
    "# Rlist = []\n",
    "\n",
    "start = time.perf_counter()\n",
    "\n",
    "with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "    results = executor.map(adbc_mapper, AD1files)\n",
    "    for r in results:\n",
    "        Alist.append(r)\n",
    "    \n",
    "\n",
    "\n",
    "finish = time.perf_counter()\n",
    "print(f'finished in {round(finish-start, 2)} seconds')\n",
    "print(len(Alist))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9973484f",
   "metadata": {},
   "outputs": [],
   "source": [
    "A0 = Alist[0]\n",
    "A0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ef4fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make df out of each fastq file\n",
    "\n",
    "Rlist = []\n",
    "\n",
    "start = time.perf_counter()\n",
    "\n",
    "with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "    results = executor.map(rbc_finder, RPTR1files)\n",
    "    for r in results:\n",
    "        Rlist.append(r)\n",
    "    \n",
    "\n",
    "finish = time.perf_counter()\n",
    "print(f'finished in {round(finish-start, 2)} seconds')\n",
    "print(len(Rlist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361158fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "R0 = Rlist[0]\n",
    "R0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f3a972",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biopython",
   "language": "python",
   "name": "biopython"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
